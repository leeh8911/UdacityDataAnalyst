{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outline\n",
    "**Gathering** data is the first step in data wrangling. Before gathering, we have no data, and after it, we do.\n",
    "\n",
    "Gathering data varies from project to project. Sometimes you're just given data, or pointed to it like I've done for you throughout this course. Sometimes you need to search for the right data for your project. Sometimes the data you need isn't readily available, and you need to generate it yourself somehow. When you do find your data, it's not unusual for it to be spread across several different sources and file formats, which makes things tricky when organizing the data in your programming environment.\n",
    "\n",
    "For these reasons and more, gathering can be tricky. In this lesson, which is likely the most technically challenging lesson of the course, you'll acquire the coding skills and general craftiness required to conquer the vast majority of gathering scenarios you'll come across in the future. This is going to be hard sometimes, and that's okay. Stick with it and don't hesitate to reach out for help.\n",
    "\n",
    "**This lesson will be structured as follows:**\n",
    "\n",
    "* First, we'll pose a few questions.\n",
    "* Then you'll explore the source of each piece of data we need to answer those questions, each piece from a different source and in a different format.\n",
    "* Then you'll learn about the structure of each file format.\n",
    "* Then you'll learn how to handle that file format using Python and its libraries.\n",
    "* Then you'll actually gather each piece of data to later join together to create your master dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigating Your Working Directory and File I/O\n",
    "## Navigating Your Working Directory and File I/O\n",
    "Before you continue on with this lesson, make sure you are comfortable working with your computer's command line interface to access files and folders, and also with reading and writing to files (i.e. part of File I/O or input/output) in Python. It can be extremely frustrating getting bogged down in these seemingly trivial topics.\n",
    "\n",
    "## Command Line\n",
    "For the command line interface, here are three excellent resources that I recommend. Pick whichever suits you best:\n",
    "\n",
    "* Our short [Linux Command Line Basics](https://www.udacity.com/course/linux-command-line-basics--ud595) course (for Linux and Mac users)\n",
    "* [Navigating the Terminal: A Gentle Introduction](https://computers.tutsplus.com/tutorials/navigating-the-terminal-a-gentle-introduction--mac-3855) by Marius Masalar (for Mac users)\n",
    "* [Command Prompt - How to use the simple, basic commands](http://www.digitalcitizen.life/command-prompt-how-use-basic-commands) by Codrut Neagu (for Windows users)\n",
    "\n",
    "## File I/O\n",
    "For reading from and writing to files in Python:\n",
    "\n",
    "* The [\"Reading and Writing Files\"](https://classroom.udacity.com/nanodegrees/nd002/parts/762c0200-e8a7-425b-be49-7080cc533c7d/modules/d2268785-db9d-4aaa-ab44-afec79099d7d/lessons/62fec647-9f0e-4551-8752-2139e2d4eb5f/concepts/43991399-3df7-48cf-a10c-792921e1b6bf) concept in Lesson 6 (\"Scripting\") of our [Prerequisite: Python](https://classroom.udacity.com/nanodegrees/nd002/parts/762c0200-e8a7-425b-be49-7080cc533c7d) course found in the Extracurricular section\n",
    "\n",
    "Feel free to skip these resources and continue with this lesson if you're familiar already."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flat File Structure\n",
    "Flat files contain tabular data in plain text format with one data record per line and each record or line having one or more fields. These fields are separated by delimiters, like commas, tabs, or colons.\n",
    "\n",
    "**Advantages of flat files** include:\n",
    "\n",
    "* They're text files and therefore human readable.\n",
    "* Lightweight.\n",
    "* Simple to understand.\n",
    "* Software that can read/write text files is ubiquitous, like text editors.\n",
    "* Great for small datasets.\n",
    "\n",
    "**Disadvantages of flat files**, in comparison to relational databases, for example, include:\n",
    "\n",
    "* Lack of standards.\n",
    "* Data redundancy.\n",
    "* Sharing data can be cumbersome.\n",
    "* Not great for large datasets (see \"When does small become large?\" in the Cornell link in More Information).\n",
    "\n",
    "> More Information\n",
    "> * [Professor Excel: XML & ZIP: Explore Your Excel Workbooks File Structure](http://professor-excel.com/xml-zip-excel-file-structure/)\n",
    "> * [Cornell: Relational Databases - Not your Father's Flat Files](https://www.cac.cornell.edu/education/Training/DataAnalysis/RelationalDatabases.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source: Web Scraping\n",
    "The two main ways to work with HTML files are:\n",
    "\n",
    "* Saving the HTML file to your computer (using the [Requests](http://docs.python-requests.org/en/master/) library for example) library and reading that file into a `BeautifulSoup` constructor\n",
    "* Reading the HTML response content directly into a `BeautifulSoup` constructor (again using the Requests library for example)\n",
    "\n",
    "You'll learn how this Requests code works under the hood shortly in “Downloading Files from The Internet.”\n",
    "\n",
    "For this lesson, you’re going to do neither of these. I've downloaded all of the Rotten Tomatoes HTML files for you and put them in a folder called rt_html in the Jupyter Notebooks in the Udacity classroom. If you want to work outside of the classroom, **download [this zip file](https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59ca6b7b_rt-html/rt-html.zip) and extract the rt_html folder. I recommend that you do and open the HTML files in your preferred text editor (e.g. [Sublime](https://www.sublimetext.com/), which is free) to inspect the HTML for the quizzes ahead.**\n",
    "\n",
    "The rt_html folder contains the Rotten Tomatoes HTML for each of the Top 100 Movies of All Time as the list stood at the most recent update of this lesson. I'm giving you these historical files because the ratings will change over time and there will be inconsistencies with the recorded lesson videos. Also, a web page's HTML is known to change over time. Scraping code can break easily when web redesigns occur, which makes scraping brittle and not recommended for projects with longevity. So just use these HTML files provided to you and pretend like you saved them yourself with one of the methods described above.\n",
    "\n",
    "> More Information\n",
    "> * [Towards Data Science: Ethics in Web Scraping](https://medium.com/towards-data-science/ethics-in-web-scraping-b96b18136f01)\n",
    "> * [David Venturi: Screen scraping was the first \"magical\" thing that drew me to programming](https://twitter.com/venturidb/status/734757220525715456)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HTML File Structure\n",
    "The Hypertext Markup Language (or HTML) is the language used to create documents for the World Wide Web.\n",
    "\n",
    "Let's turn to [Cameron Pittman](https://blog.udacity.com/2015/03/3-web-developers-built-careers-scratch-part-two-cameron-pittman.html), an instructor and Full Stack Engineer at Udacity, to introduce the basic structure of HTML files. The three short videos below are all you need to know to start web scraping. If you'd like to learn more, or are feeling like there are knowledge gaps you'd like to fill in, I encourage you to check out Cameron's \"Intro to HTML and CSS\" course. You can find it [here](https://www.udacity.com/course/intro-to-html-and-css--ud304).\n",
    "\n",
    "As you're following along with the video, open up one of the HTML files you just downloaded in a text editor (like Sublime) and look for similarities in the HTML document that Cameron uses as an example. We'll do this together soon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source: Downloading Files from the Internet\n",
    "## HTTP (Hypertext Transfer Protocol)\n",
    "HTTP, the Hypertext Transfer Protocol, is the language that web browsers (like Chrome or Safari) and web servers (basically computers where the contents of a website are stored) speak to each other. Every time you open a web page, or download a file, or watch a video, it's HTTP that makes it possible.\n",
    "\n",
    "HTTP is a request/response protocol:\n",
    "\n",
    "* Your computer, a.k.a. the client, sends a request to a server for some file. For this lesson: \"Get me the file **1-the-wizard-of-oz-1939-film.txt**\", for example. GET is the name of the HTTP request method (of which there are multiple) used for retrieving data.\n",
    "* The web server sends back a response. If the request is valid: \"Here is the file you asked for:\", then followed by the contents of the **1-the-wizard-of-oz-1939-film.txt** file itself.\n",
    "![img](./assets/l2_12.png)\n",
    "\n",
    "If you'd like to learn more, or are feeling like there are knowledge gaps you'd like to fill in, I encourage you to check out the following videos in our free [Web Development course](https://classroom.udacity.com/courses/cs253) in Lesson 1 (\"How the Web Works\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text File Structure\n",
    "## Encodings and Character Sets Articles\n",
    "[The Absolute Minimum Every Software Developer Absolutely, Positively Must Know About Unicode and Character Sets (No Excuses!)](https://www.joelonsoftware.com/2003/10/08/the-absolute-minimum-every-software-developer-absolutely-positively-must-know-about-unicode-and-character-sets-no-excuses/) by Joel Spolsky\n",
    "An excerpt:\n",
    "\n",
    "> **The Single Most Important Fact About Encodings**\n",
    "\n",
    "> If you completely forget everything I just explained, please remember one extremely important fact. It does not make sense to have a string without knowing what encoding it uses. You can no longer stick your head in the sand and pretend that “plain” text is ASCII.\n",
    "\n",
    "> **There Ain’t No Such Thing As Plain Text**\n",
    "\n",
    "> If you have a string, in memory, in a file, or in an email message, you have to know what encoding it is in or you cannot interpret it or display it to users correctly.\n",
    "\n",
    "> Almost every stupid “my website looks like gibberish” or “she can’t read my emails when I use accents” problem comes down to one naive programmer who didn’t understand the simple fact that if you don’t tell me whether a particular string is encoded using UTF-8 or ASCII or ISO 8859-1 (Latin 1) or Windows 1252 (Western European), you simply cannot display it correctly or even figure out where it ends. There are over a hundred encodings and above code point 127, all bets are off.”\n",
    "\n",
    "[What Every Programmer Absolutely, Positively Needs To Know About Encodings And Character Sets To Work With Text](http://kunststube.net/encoding/)\n",
    "\n",
    "> An article by Joel Spolsky entitled The Absolute Minimum Every Software Developer Absolutely, Positively Must Know About Unicode and Character Sets (No Excuses!) is a nice introduction to the topic and I greatly enjoy reading it every once in a while. I hesitate to refer people to it who have trouble understanding encoding problems though since, while entertaining, it is pretty light on actual technical details. I hope this article can shed some more light on what exactly an encoding is and just why all your text screws up when you least need it.\n",
    "\n",
    "> Any character can be encoded in many different bit sequences and any particular bit sequence can represent many different characters, depending on which encoding is used to read or write them. The reason is simply because different encodings use different numbers of bits per characters and different values to represent different characters.”\n",
    "\n",
    "## Unicode and Python\n",
    "In Python 3, there is:\n",
    "\n",
    "* one text type: `str`, which holds Unicode data and\n",
    "* two byte types: `bytes` and `bytearray`\n",
    "\n",
    "The Stack Overflow answers [here](https://stackoverflow.com/questions/6224052/what-is-the-difference-between-a-string-and-a-byte-string) explain the different use cases well.\n",
    "\n",
    "## More Information\n",
    "* If you’re still confused about the difference between character sets and encoding, check out these articles:\n",
    "    * [The difference between UTF-8 and Unicode?](http://www.differencebetween.net/technology/difference-between-unicode-and-utf-8/)\n",
    "    * [More About Unicode in Python 2 and 3](http://lucumr.pocoo.org/2014/1/5/unicode-in-2-and-3/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Files in Python\n",
    "> More Information\n",
    "> * [Stack Overflow: Best Practices for Opening Files in Python](https://stackoverflow.com/a/22288895)\n",
    "> * [Stack Overflow: The Correct, Fully Pythonic Way to Read a File](https://stackoverflow.com/a/8010133)\n",
    "> * [Stack Overflow: Iterables and Iterators](https://stackoverflow.com/a/16994568)\n",
    "> * [Wikipedia: Glob programming](https://en.wikipedia.org/wiki/Glob_(programming)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Source: APIs(Application Programming Interfaces)\n",
    "## MediaWiki API\n",
    "\n",
    "MediaWiki has a great [tutorial](https://www.mediawiki.org/wiki/API:Tutorial) on their website on how their API calls are structured. It's a nice and simple example and they explain the various moving parts:\n",
    "\n",
    "* The endpoint (important takeaway: there is nothing special about this URL!)\n",
    "* The format\n",
    "* The action\n",
    "* Action-specific parameters\n",
    "\n",
    "Go and read that example and then come back to the classroom.\n",
    "\n",
    "Done reading? Great! Though they say that is a \"simple example,\" it could definitely be simpler! This is where access libraries, also known as client libraries or even just libraries (as in \"Twitter API libraries\"), come into play and make our lives easier.\n",
    "\n",
    "## wptools Library\n",
    "\n",
    "There are a bunch of different access libraries for MediaWiki to satisfy the variety of programming languages that exist. Here is a [list](https://www.mediawiki.org/wiki/API:Client_code#Python) for Python. This is pretty standard for most APIs. Some libraries are better than others, which again, is standard. For a MediaWiki, the most up to date and human readable one in Python is called [wptools](https://github.com/siznax/wptools). The analogous relationship for Twitter is:\n",
    "\n",
    "* MediaWiki API → wptools\n",
    "* Twitter API → tweepy\n",
    "wptools has an even simpler tutorial on their GitHub page using the [Mahatma Gandhi Wikipedia page](https://en.wikipedia.org/wiki/Mahatma_Gandhi) as a working example.\n",
    "\n",
    "To get a `page` object, the [usage](https://github.com/siznax/wptools/wiki/Usage#page-usage) is as follows:\n",
    "```Python\n",
    "page = wptools.page('Mahatma_Gandhi')\n",
    "```\n",
    "\n",
    "...where *'Mahatma_Gandhi'* is the last bit of the Wikipedia URL for that page (https://en.wikipedia.org/wiki/Mahatma_Gandhi). This `page` object has methods that can get us various pieces of data about that Wikipedia page, including all of the images on the page. To get all of the data:\n",
    "\n",
    ">Simply calling get() on a page will automagically fetch extracts, images, infobox data, wikidata, and other metadata via the MediaWiki, Wikidata, and RESTBase APIs.\n",
    "```Python\n",
    "page = wptools.page('Mahatma_Gandhi').get()\n",
    "```\n",
    "Or if you already have a page object assigned to `page`:\n",
    "```Python\n",
    "page.get()\n",
    "```\n",
    "`page` now has the following attributes, which can be accessed using dot notation through `.data`:\n",
    "![img](./assets/l2_15.png)\n",
    "\n",
    "`page.data['image']`, for example, would return a list of data for six images on this specific Wikipedia page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JSON FILE Structure\n",
    "More Information\n",
    "* [Mashery: API Data Exchange: XML vs. JSON](https://www.tibco.com/blog/2014/01/23/api-data-exchange-xml-vs-json/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JSON Files in Python\n",
    "## More JSON in Python\n",
    "For the example in this lesson, JSON data was sourced from an API. That isn't always the case, though! Sometimes you're given a text file with human readable JSON within it. For this situation, the [*json*](http://docs.python-guide.org/en/latest/scenarios/json/) library is indispensable. It can parse JSON from strings or files and it can parse JSON into a Python dictionary or list. It can also convert Python dictionaries or lists into JSON strings. The tutorial on the linked documentation page is handy. This [Reading and Writing JSON to a File in Python](http://stackabuse.com/reading-and-writing-json-to-a-file-in-python/) article from Stack Abuse is also great, which outlines `json.dump`, `json.dumps`, `json.load`, and `json.loads` (four key json library methods) well.\n",
    "\n",
    "pandas also has JSON functions (the `read_json` function and the `to_json` DataFrame method), but the hierarchical advantage of JSON is wasted in pandas' tabular DataFrame so the uses are limited."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mashup: APIs, Downloading Files Programmatically, JSON\n",
    "## Mashup: APIs, Downloading Files Programmatically, and JSON\n",
    "With APIs, downloading files programmatically from the internet, and JSON under your belt, you now have all of the knowledge to download all of the movie poster images for the Roger Ebert review word clouds. This is your next task.\n",
    "\n",
    "There are two key things to be aware of before you begin:\n",
    "\n",
    "##  Wikipedia Page Titles\n",
    "To access Wikipedia page data via the MediaWiki API with *wptools* (*phew*, that was a mouthful), you need each movie's Wikipedia page title, i.e., what comes after the last slash in **en.wikipedia.org/wiki/** in the URL. For this lesson, I've compiled all of these titles for each of the movies in the Top 100 for you.\n",
    "![img](./assets/l2_18.png)\n",
    "\n",
    "## Downloading Image Files\n",
    "Downloading images may seem tricky from a reading and writing perspective, in comparison to text files which you can read line by line, for example. But in reality, image files aren't special—they're just binary files. To interact with them, you don't need special software (like Photoshop or something) that \"understands\" images. You can use regular file opening, reading, and writing techniques, like this:\n",
    "```Python\n",
    "import requests\n",
    "r = requests.get(url)\n",
    "with open(folder_name + '/' + filename, 'wb') as f:\n",
    "        f.write(r.content)\n",
    "```\n",
    "But this technique can be error-prone. It will work most of the time, but sometimes the file you write to will be damaged. This happened to me when preparing this lesson:\n",
    "![img](./assets/l2_18_1.png)\n",
    "\n",
    "This type of error is why the requests library maintainers [recommend](http://docs.python-requests.org/en/latest/user/quickstart/#binary-response-content) using the [PIL](https://pillow.readthedocs.io/) library (short for Pillow) and `BytesIO` from the io library for non-text requests, like images. They recommend that you access the response body as bytes, for non-text requests. For example, to create an image from binary data returned by a request:\n",
    "```Python\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "r = requests.get(url)\n",
    "i = Image.open(BytesIO(r.content))\n",
    "```\n",
    "Though you may still encounter a similar file error, this code above will at least warn us with an error message, at which point we can manually download the problematic images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing Data\n",
    "Storing is usually done after cleaning, but it's not always done, which excludes it from being a core part of the data wrangling process. Sometimes you just analyze and visualize and leave it at that, without saving your new data.\n",
    "\n",
    "Again, because storing is performed on cleaned data, we could cover this at the end of Lesson 4 (\"Cleaning Data\"). But since we're covering file formats in this lesson, let's cover it here.\n",
    "\n",
    "Imagine you've assessed and cleaned your data, which includes merging all of these separate pieces of data, which as I mentioned in the last video I took care of behind the scenes for you. What do you want to do next?\n",
    "\n",
    "The advantages and disadvantages of flat files were discussed earlier in the lesson in the Flat File Structure concept. One of the advantages:\n",
    "\n",
    ">Great for small datasets.\n",
    "\n",
    "And one of the disadvantages:\n",
    "\n",
    ">Sharing data can be cumbersome.\n",
    "\n",
    "Given the size of this dataset and that it likely won't be shared often, saving to a flat file like a CSV is probably the best solution. With pandas, saving your gathered data to a CSV file is easy. The `to_csv` [DataFrame method](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.to_csv.html) is all you need and the only parameter required to save a file on your computer is the file path to which you want to save this file. Often specifying `index=False` is necessary too if you don't want the DataFrame index showing up as a column in your stored dataset. If you had a DataFrame, df, and wanted to save to a file named dataset.csv with no index column:\n",
    "```Python\n",
    "df.to_csv('dataset.csv', index=False)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relational Database Structure\n",
    "A database is an organized collection of data that is structured to facilitate the storage, retrieval, modification, and deletion of data. There are two main types of databases: relational databases and non-relational databases, with relational being the most popular. SQL, or Structured Query Language, is the standard language for communicating with relational databases.\n",
    "\n",
    "Let’s turn to [Derek Steer](https://twitter.com/dereksteer), co-founder and CEO of [Mode Analytics](https://modeanalytics.com/) (a company that is building software for SQL-based data analysis), to introduce the basic structure of relational databases, their advantages and disadvantages, and how you can interact with them using SQL. The ~5 minutes of videos and text below are all you need to know for this lesson.\n",
    "\n",
    "Databases and SQL are topics that deserve a full course. If you'd like to learn more, enroll in the [Data Foundations Nanodegree](https://www.udacity.com/course/data-foundations-nanodegree--nd100) program or the [Data Analyst Nanodegree program](https://www.udacity.com/course/data-analyst-nanodegree--nd002) (if you aren't already) to access Derek's SQL for Data Analysis course.\n",
    "\n",
    "I've selected a subset of videos from that course most relevant to Data Wrangling for you to preview here. As you’re following along with the video, imagine how the Rotten Tomatoes master dataset would be represented and how you might query it to get information. There is also a SQL Explorer Workspace following the videos where you can make queries on the same PostgreSQL database that Derek mentions.\n",
    "\n",
    "> More Information\n",
    "> * [Cornell: Relational Databases - Not your Father’s Flat Files](https://www.cac.cornell.edu/education/Training/DataAnalysis/RelationalDatabases.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relational Databases in Python\n",
    "## Data Wrangling and Relational Databases\n",
    "In the context of data wrangling, we recommend that databases and SQL only come into play for gathering data or storing data. That is:\n",
    "\n",
    "* **Connecting to a database and importing data** into a pandas DataFrame (or the analogous data structure in your preferred programming language), then assessing and cleaning that data, or\n",
    "* **Connecting to a database and storing data** you just gathered (which could potentially be from a database), assessed, and cleaned\n",
    "\n",
    "These tasks are especially necessary when you have large amounts of data, which is where SQL and other databases excel over flat files.\n",
    "\n",
    "The two scenarios above can be further broken down into three main tasks:\n",
    "\n",
    "* Connecting to a database in Python\n",
    "* Storing data **from** a pandas DataFrame **in** a database to which you're connected, and\n",
    "* Importing data **from** a database to which you're connected **to** a pandas DataFrame\n",
    "\n",
    "## This Lesson\n",
    "For the example in this lesson, we're going to do these in order:\n",
    "\n",
    "1. Connect to a database. We'll connect to a SQLite database using [SQLAlchemy](https://www.sqlalchemy.org/), a database toolkit for Python.\n",
    "1. Store the data in the cleaned master dataset in that database. We'll do this using pandas' `to_sql` DataFrame method.\n",
    "1. Then read the brand new data in that database back into a pandas DataFrame. We'll do this using pandas' `read_sql` function.\n",
    "\n",
    "The third one isn’t necessary for this lesson, but often in the workplace, instead of having to download files, scrape web pages, hit an API, etc., you're given a database right at the beginning of a project.\n",
    "\n",
    "All three of these tasks will be introduced and carried out in the Jupyter Notebook below. These are not quizzes. All of the code is provided for you. Your job is to read and understand each comment and line of code, then run the code.\n",
    "\n",
    "## Data Wrangling in SQL?\n",
    "Data wrangling can actually be performed in SQL. We believe that pandas is better equipped for gathering (pandas has a huge simplicity advantage in this area), assessing, and cleaning data, so we usually recommend that you use pandas if given the choice. If wrangling in a work setting, sometimes your tool of choice for data wrangling depends on your company infrastructure, though.\n",
    "\n",
    "Here is an interesting [Reddit thread that debates pandas vs. SQL](https://www.reddit.com/r/Python/comments/1tqjt4/why_do_you_use_pandas_instead_of_sql/) in general and touches on several topics related to data wrangling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other File Formats\n",
    "The types of files you mastered in this lesson are the ones you'll interact with for the vast majority of your wrangling projects in the future. Again, these were:\n",
    "\n",
    "* Flat files (e.g. CSV and TSV)\n",
    "* HTML files\n",
    "* JSON files\n",
    "* TXT files\n",
    "* Relational database files\n",
    "\n",
    "Additional, less common file formats include:\n",
    "\n",
    "* [Excel files](https://www.lifewire.com/what-is-an-xlsx-file-2622540)\n",
    "* [Pickle files](https://stackoverflow.com/questions/7501947/understanding-pickling-in-python)\n",
    "* [HDF5 files](http://neondataskills.org/HDF5/About)\n",
    "* [SAS files](http://whatis.techtarget.com/fileformat/SAS-SAS-program-file)\n",
    "* [STATA files](http://faculty.econ.ucdavis.edu/faculty/cameron/stata/stataintro.html)\n",
    "\n",
    "pandas has [functions](http://pandas.pydata.org/pandas-docs/stable/api.html#input-output) to read (and write, to most of them) these files. Also, you now have the foundational understanding of **gathering** and file formats in general, so learning these additional formats won't be too hard if you need them."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
