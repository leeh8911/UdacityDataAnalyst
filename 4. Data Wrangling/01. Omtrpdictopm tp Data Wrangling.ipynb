{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definition And An Analogy\n",
    "## A Definition\n",
    "Wrangling is a weird word. Let’s check the definition. This is exactly what I did when I first heard the term and was perplexed just as you may be right now.\n",
    "![img](./assets/l1_3.gif)\n",
    "\n",
    "So wrangling means to round up, herd, or take charge of livestock, like horses or sheep. Let's focus in on the sheep example.\n",
    "\n",
    "A shepherd's main goals are to get their sheep to their pastures to let them graze, guide them to market to shear them, and put them in the barn to sleep. Before any of that though, they must be rounded up in a nice and organized group. The consequences if they're not? These tasks take longer. If they're all scattered, some could also run off and get lost. A wolf could even sneak into the pack and feast on a few of them.\n",
    "\n",
    "## An Analogy\n",
    "The same idea of organizing before acting is true for those who are shepherds of data. We need to wrangle our data for good outcomes, otherwise there could be consequences. If we analyze, visualize, or model our data before we wrangle it, our consequences could be making mistakes, missing out on cool insights, and wasting time. So best practices say wrangle. Always.\n",
    "\n",
    "The development of Python and its libraries have made wrangling easier. In this course, you'll learn how to wrangle data like modern day data professionals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">More Information\n",
    "> * [Wikipedia: Click-through rate (CTR)](https://en.wikipedia.org/wiki/Click-through_rate)\n",
    "> * [Charlie Park: Edward Tufte's \"Slopegraphs\"](http://charliepark.org/slopegraphs/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gather\n",
    "Congratulations! You've conquered the first step of data wrangling: **gathering data**. For this dataset, this meant:\n",
    "\n",
    "* downloading a file from the internet, which in this case was a zip file from Kaggle,\n",
    "* opening a Jupyter Notebook,\n",
    "* unzipping the zip file using Python,\n",
    "* then importing the extracted CSV file into a pandas DataFrame in the Jupyter Notebook.\n",
    "\n",
    "You will frequently put these skills that you’ve acquired to frequent use in your data career.\n",
    "\n",
    "In **lesson 2**, you'll gather data using more advanced methods, like downloading files programmatically, scraping data from web pages, and accessing data from an API. You'll learn how to handle the next most popular file formats beyond CSV, like HTML, JSON, text files, and databases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assess\n",
    "Congratulations! That's it for the second step of data wrangling: **assessing data**. You assessed data, both visually and programmatically, and identified data quality and tidiness issues. The issues you identified were:\n",
    "\n",
    "* Nondescriptive column headers\n",
    "* Missing values (i.e. NaNs)\n",
    "* Inconsistent representations of values, specifically \"As soon as possible\" and other similar values to \"ASAP\" in the StartDate column for this dataset\n",
    "* A messy (i.e. untidy) dataset\n",
    "\n",
    "There are more issues that we didn’t assess—this dataset is fairly dirty and messy—so we can’t fix everything right now. That’s okay for the purpose of this walkthrough. You've developed an eye for spotting data quality and tidiness issues, which is applicable to every dataset you'll come across in the future.\n",
    "\n",
    "In **lesson 3**, you'll identify every common data quality and tidiness issue imaginable. You'll also refine your assessing skills. You'll be able to categorize data quality issues using four core data quality metrics. You'll also enhance your programmatic assessment skills using the most common programmatic assessment functions in pandas, including simple plotting techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean\n",
    "Congratulations! You just finished cleaning, which is usually the most code-heavy part of the data wrangling process. You converted your observations from the assess step into defined problems, translated these definitions to sophisticated code to fix these problems, then tested your dataset using code—even using something software engineers use, assert statements—to make sure the operations worked.\n",
    "\n",
    "You'll be cleaning lots more data in your future in data. So much of the world's data is dirty and messy.\n",
    "\n",
    "The issues you cleaned in this lesson were only a subset of the most common data quality and tidiness issues. In **lesson 4**, you'll clean every common data quality and tidiness issue imaginable and you'll do it using advanced pandas techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storing Data (Optional)\n",
    "After reassessing your data and revisiting any steps of the data wrangling process deemed necessary, storing your cleaned data can be the next logical step. Storing data is important if you need to use your cleaned data in the future.\n",
    "\n",
    "Storing data isn't always necessary, though. Sometimes the Jupyter Notebook that you gathered, assessed, cleaned, analyzed, and visualized your data in, plus the original data files is good enough. Sometimes the analysis and visualization are the final products and you won't be using the cleaned data any further. If you ever want to reproduce the analysis, the Jupyter Notebook suffices.\n",
    "\n",
    "Storing your data, in files and databases for example, will be covered in detail in a later lesson in the course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangling vs. EDA\n",
    "At another point in the Data Analyst Nanodegree or if you're taking this course individually, another point in your data journey, you will encounter a topic called exploratory data analysis (EDA). If you've encountered EDA already you might be thinking: data wrangling seems very similar to exploratory data analysis. And that's because they are very similar and often get confused.\n",
    "\n",
    "Here is one definition of EDA: an analysis approach that focuses on identifying general patterns in the data, and identifying outliers and features of the data that might not have been anticipated.\n",
    "\n",
    "So where does **data wrangling** end and **EDA** start?\n",
    "\n",
    "**Data wrangling** is about gathering the right pieces of data, assessing your data's quality and structure, then modifying your data to make it clean. But the assessments you make and convert to cleaning operations won't make your analysis, viz, or model better, though. The goal is to just make them possible, i.e., functional.\n",
    "\n",
    "**EDA** is about exploring your data to later augment it to maximize the potential of our analyses, visualizations, and models. When exploring, simple visualizations are often used to summarize your data's main characteristics. From there you can do things like remove outliers and create new and more descriptive features from existing data, also known as [feature engineering](https://en.wikipedia.org/wiki/Feature_engineering). Or detect and remove outliers so your model's fit is better.\n",
    "\n",
    "In practice, wrangling and EDA can and often do occur together, but we're going to separate them for teaching purposes.\n",
    "\n",
    "# ETL\n",
    "You also may have heard of the [extract-transform-load process](https://en.wikipedia.org/wiki/Extract,_transform,_load) also known as ETL. ETL differs from data wrangling in three main ways:\n",
    "\n",
    "1. The users are different\n",
    "1. The data is different\n",
    "1. The use cases are different\n",
    "\n",
    "This article ([Data Wrangling Versus ETL: What’s the Difference?](https://tdwi.org/articles/2017/02/10/data-wrangling-and-etl-differences.aspx)) by Wei Zhang explains these three differences well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling Summary\n",
    "[Data wrangling template link](https://d17h27t6h515a5.cloudfront.net/topher/2017/September/59cebf3f_data-wrangling-template/data-wrangling-template.ipynb)\n",
    "\n",
    "## Gather\n",
    "* Depending on the source of your data, and what format it's in, the steps in gathering data vary.\n",
    "* High-level gathering process: obtaining data (downloading a file from the internet, scraping a web page, querying an API, etc.) and importing that data into your programming environment (e.g., Jupyter Notebook).\n",
    "\n",
    "## Assess\n",
    "* Assess data for:\n",
    "    * Quality: issues with content. Low quality data is also known as dirty data.\n",
    "    * Tidiness: issues with structure that prevent easy analysis. Untidy data is also known as messy data. Tidy data requirements:\n",
    "        1. Each variable forms a column.\n",
    "        1. Each observation forms a row.\n",
    "        1. Each type of observational unit forms a table.\n",
    "    * Types of assessment:\n",
    "        * Visual assessment: scrolling through the data in your preferred software application (Google Sheets, Excel, a text editor, etc.).\n",
    "        * Programmatic assessment: using code to view specific portions and summaries of the data (pandas' head, tail, and info methods, for example).\n",
    "\n",
    "## Clean\n",
    "* Types of cleaning:\n",
    "    * Manual (not recommended unless the issues are single occurrences)\n",
    "    * Programmatic\n",
    "* The programmatic data cleaning process:\n",
    "    1. Define: convert our assessments into defined cleaning tasks. These definitions also serve as an instruction list so others (or yourself in the future) can look at your work and reproduce it.\n",
    "    1. Code: convert those definitions to code and run that code.\n",
    "    1. Test: test your dataset, visually or with code, to make sure your cleaning operations worked.\n",
    "* Always make copies of the original pieces of data before cleaning!\n",
    "\n",
    "## Reassess and Iterate\n",
    "* After cleaning, always reassess and iterate on any of the data wrangling steps if necessary.\n",
    "\n",
    "## Store (Optional)\n",
    "* Store data, in a file or database for example, if you need to use it in the future."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
