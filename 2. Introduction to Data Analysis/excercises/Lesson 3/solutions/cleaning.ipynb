{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Example\n",
    "Let's explore ways of fixing some common issues in data. Here's a toy dataset I created for this lesson. It has eleven instances of user-product interactions online, recording whether the user liked the product, how long they viewed the product, whether it was on a website or through a mobile app, and what time they started viewing the product. Can you spot any potential issues in this data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('product_view_data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's address three issues in this dataset that are quite common in the real world\n",
    "- Missing data (in the `view_duration` columns)\n",
    "- Duplicates (rows 3 and 4)\n",
    "- Incorrect Datatypes (`timestamp` is represented as a string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling null values\n",
    "In the dataframe above, you can see null values represented as `NaN`, which stands for not a number. From the output of `df.info()` you can see that there are 8 non-null values, which leaves 3 null values of the 11 entries. [Missing data](https://en.wikipedia.org/wiki/Missing_data) is an issue that should be handled differently depending on several factors, such as the reason those values are missing and whether the occurrences seem random. One way of handling them is [imputing](https://en.wikipedia.org/wiki/Imputation_(statistics) them with the mean. You can do this quickly and efficiently with a convenient function from Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the mean of the column with missing data\n",
    "mean = df['view_duration'].mean()\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# replace NaN values with the mean\n",
    "df['view_duration'].fillna(mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the dataframe now - did this fix the problem?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of making changes to the original column, it just returned a new column with the changes, which we didn't store anywhere. To keep the changes, make sure to assign it to the original like this:\n",
    "\n",
    "`df['view_duration'] = df['view_duration'].fillna(mean)`\n",
    "\n",
    "Alternatively, you can use an extra parameter as shown in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# replace NaN values and make changes in place\n",
    "df['view_duration'].fillna(mean, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Success!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping Duplicates\n",
    "There are multiple reasons you may end up with duplicated data, like combined data sources or human error. Here's a simple scenario where two rows (3 and 4) are identical. This toy dataset is small enough for us to count visually. For bigger datasets, you can use this function to see which rows are duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# By default, this marks duplicates as True excluding the first instance,\n",
    "# and it considers a row to be a duplicate only if the values in all\n",
    "# columns match. You can change both of these with its parameters.\n",
    "df.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For larger datasets, it would probably be more helpful to get a count\n",
    "# of duplicates in the dataset like this\n",
    "sum(df.duplicated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You can drop duplicated data with this function. Remember to use\n",
    "# assigned it to the original dataframe or use inplace to keep changes!\n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! You can see we've dropped row 4 - the row marked as a duplicate. This was a simple situation where the entire row was identical. You could imagine duplicated data scenarios that are a bit more complicated.\n",
    "\n",
    "For example, let's say we had data on patients from a hospital. What happens when you come across two rows with the same patient id but different data on medical exam results? Do you combine them? Only keep the latest one? This is a situation you'd have to investigate more. For this scenario, you'd likely identify duplicates only based on the column recording the patient's id. You can use the `subset` paramater in [duplicated()](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.duplicated.html) and [drop_duplicates()](http://pandas.pydata.org/pandas-docs/version/0.17.1/generated/pandas.DataFrame.drop_duplicates.html) to do this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting to datetime\n",
    "Incorrect datatypes is also a problem data analysts frequently come across. In this case, the timestamps are represented as strings instead of datetimes. This isn't critical, but datetimes are much more convenient to work with if you want to extract specific information from them or filter them more easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This shows the datatype of timestamp is not yet datetime\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Let's use this awesome function to convert this column to datetime\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now we can see timestamp is represented as a datetime\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that even if you save this to a csv file after making this change, it will be read as a string by default the next time you open it. You'll still have to convert it after opening the csv file, or use parameters like `parse_dates` in the [read_csv()](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html) function. [to_datetime()](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.to_datetime.html) provides parameters for more options if the strings you have to parse are formatted unconventionally."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
